## Week 2: Python Preliminary

利用python数据结构（list, dict, set等）完成简单的文本分析任务

1. 提供了京东商品评论数据集，见资源/data/jd_comments.rar

2. 一行一条评论

3. 一行可以视为一个文档（document)

4. 读入所有文档并分词（需要jieba)

5. 过滤停用词，统计词频（停用词表自行检索并构建，如提供的示例stopwords_list.txt）

6. 根据词频进行特征词筛选，如只保留高频词，删除低频词，并得到特征词组成的特征集

7. 利用特征集为每一条评论生成向量表示，可以是0，1表示（one-hot)也可以是出现次数的表示

8. 计算一下不同评论之间的距离（自定义，如欧氏或余弦），找到所有评论的“重心”或者所有文档中的代表性文档并输出原文。

9. （附加）. 能不能实现关键词的词云可视化？(WordCloud)

  注意：通过函数进行封装，并在main函数中调用